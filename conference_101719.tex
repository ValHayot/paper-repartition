\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{algorithmic, algorithm}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{ Experimenting sequential algorithms to optimize the scheduling of multidimensional array processing in Dask }

\author{\IEEEauthorblockN{1\textsuperscript{st} Timothée Guédon}
\IEEEauthorblockA{\textit{Department of Computer Science and Software Engineering} \\
\textit{Concordia University}\\
Montreal, Quebec, Canada \\
t\_guedon@encs.concordia.ca}
\and
\IEEEauthorblockN{2\textsuperscript{nd} Tristan Glatard}
\IEEEauthorblockA{\textit{Department of Computer Science and Software Engineering} \\
\textit{Concordia University}\\
Montreal, Quebec, Canada \\
tristan.glatard@concordia.ca}
\and
\IEEEauthorblockN{3\textsuperscript{rd} Valérie Hayot-Sasson}
\IEEEauthorblockA{\textit{Department of Computer Science and Software Engineering} \\
\textit{Concordia University}\\
Montreal, Quebec, Canada \\
email address or ORCID}
}

\maketitle

\begin{abstract}
This document is a model and instructions for \LaTeX.
This and the IEEEtran.cls file define the components of your paper [title, text, heads, etc.]. *CRITICAL: Do Not Use Symbols, Special Characters, Footnotes,
or Math in Paper Title or Abstract.
\end{abstract}

\begin{IEEEkeywords}
component, formatting, style, styling, insert
\end{IEEEkeywords}

%----------------------------------------
\section*{Introduction}
%----------------------------------------

This document is a model and instructions for \LaTeX.
Please observe the conference page limits.

\subsection{Big Data softwares in Python}
\textbf{Spark}
\textbf{Dask}

\subsection{Selecting a Big Data software}

\subsection{Focusing on Dask}
\textbf{Scheduler selection}
\textbf{API selection}
\textbf{Which algorithm can be implemented?}
\textbf{Dask constraints and requirements}

%----------------------------------------
\section*{Related work}
%----------------------------------------

\subsection{The splitting and merging problem}
\subsection{Sequential algorithms}

%----------------------------------------
\section*{Methods}
%----------------------------------------

\subsection{Experiment 1 - assessing if there is space for improvement}

\subsection{Implementation details of the ``Clustered" strategy}
Our goal is to implement the most minor modification as possible that will provide the clustered strategy to the user. We also want our modification to be easy to use. We could try to modify internally the Dask software but a smarter way to modify the graph would be to use an optimization function. As we will see, the modification of the Dask graph by the optimization function alone would not be safe to use. That is why we need to adjust a little bit the scheduler behavior, too.

% figure of the use of the optimization function

\subsubsection{Optimization function}
Our optimization strategy consists in modifying the Dask graphs such that we force the scheduler to load contiguous data blocks in one shot, as one buffer. A parameter has to be selected along with the use of the optimization function: the buffer size. On the one hand, the buffer size is bounded by the random access memory size available. On the other hand, the user could also want to further bound the buffer size depending on the application. For example if the application is doing a cartesian product between two vectors the memory size used by the application will explose: We will switch from $O(n)$ memory consumption to $O(n^2)$.

Before stepping into the implementation details, we need to define what an ``array proxy" is. We call it array proxy inspired by the Python library nibabel. Unlike nibabel however, our proxy is not an object which can load data but it is a link to a block of the data. Going through the scheduler, this task will load the block it represents, and this block will be used for further operations.
% note to self: what about using nibabel in dask instead of loading the entire block directly? how does it work?

Internally, the optimization function is applied on the dask graph. We proceed in two steps: finding the ``array proxies" that are used in the graph, and modifying the dask graph accordingly to mutualize the data loading by the use of buffers. \\

\textbf{Finding the used array proxies} \\

% detail the process here

At the end of the search, we end up with $utility\_dicts$ contains the following dictionaries:
\begin{itemize}
  \item $array\_to\_original$: map array proxy names to the original arrays they represent
  \item $original\_array\_chunks$: map original array names to their chunk shapes
  \item $original\_array\_shapes$: map original array names to their shape
  \item $original\_array\_blocks\_shape$: map original array names to their shape in terms of blocks, i.e. the number of blocks they have in each dimension.
\end{itemize}

\textbf{Creating the buffers} \\
At this point we found the used array proxies. The idea here is to create new nodes to replace the array proxies by buffers. We can do this because the scheduler tries to leverage the data that has been loaded using a LIFO strategy: When some data has been loaded the scheduler will run all the tasks that uses this data. By doing so the data is loaded only once. By loading a large buffer in one time, we will not break this rule. We will load more data at the same time that can then be used by all the tasks that need it. Firstly, this would have been a problem if the data would be loaded several times. Secondly, it \textit{should} maximize the parallelism by enabling the computation of many tasks at the same time. This way, we reduce the probability of seeing tasks waiting for the data loading, although the beginning of computation will be delayed by the very first data loading task.

The idea is to create buffers following the clustered strategy from Hayot-Sasson et al. As we said, we want to create buffers by merging tasks that load contiguous data blocks. We therefore need to know whiwh block is contiguous with each other on the disk. To that aim we need an algorithm to convert indices in n-dimension into indices in 1 dimension for each logical block of the array that is to be loaded by a loading task i.e. which is reprensented by an array proxy. This function takes the order in which the data is stored on disk: column-major or row-major.

% algorithm 3d_to_numeric and numeric_to_3d

Given a list of used proxies, we first need to convert the indices into numeric indices using the algorithm above. We then concatenate the blocks into buffers given a maximum buffer memory size. According to the paper of reference, we should prevent the overlaping of block slices and block rows. Algorithm~\ref{algo:createbuffers} below show how we process to concatenate blocks loading.
In the following algorithm, $blocks\_used$ designates the list of integer indices of the used array proxies found in the previous section.

\begin{algorithm}
  \caption{$create\_buffers(blocks\_used)$}
  \label{algo:createbuffers}
  \begin{algorithmic}
    \STATE $blocks \leftarrow sorted(blocks used)$
    \STATE $buffers \leftarrow list()$
    \STATE $curr\_buffer \leftarrow list()$
    \STATE $prev\_block \leftarrow None$

    \WHILE{$length(blocks) > 0$}
        \STATE $b \leftarrow blocks.pop(0)$
        \IF {$start\_new\_buffer() and not empty(curr\_buffer)$}
          \STATE $buffers.append(curr\_buffer)$
          \STATE $curr\_buffer \leftarrow list()$
          \STATE $prev\_block \leftarrow None$
        \ENDIF

        \STATE $curr\_buffer.append(b)$
        \STATE $prev\_block \leftarrow b$
    \ENDWHILE

    \IF{$buffer\_size >= block\_row\_size$}
      \STATE $buffers \leftarrow concat\_rows(buffers)$
      \IF{$buffer\_size >= block\_slice\_size$}
        \STATE $buffers \leftarrow concat\_slices(buffers)$
      \ENDIF
    \ENDIF

    \RETURN $buffers$
  \end{algorithmic}
\end{algorithm}

As you can see, Algorithm~\ref{algo:createbuffers} uses three sub-algorithms: $start\_new\_buffer$ (Algorithm~\ref{algo:startnewbuffer}), $concat\_rows$ (Algorithm~\ref{algo:concatrows}) and $concat\_slices$. $start\_new\_buffer$ evaluates if we should append the current block being processed to the current buffer or if we should save the current buffer and start a new one. For example, if the buffer size has been reached, we cannot add more blocks to it. This suppose to have some information like the size of one data block in bytes, the size of the buffer in bytes etc. The $concat\_slice$ algorithm is of the same spirit than $concat\_rows$. In the following algorithm, $MAX\_BB$ designates the maximum number of blocks that can be load in one buffer and $NB\_BR$ designates the number of blocks per block row.

\begin{algorithm}
  \caption{$start\_new\_buffer(b, prev\_block, MAX\_BB, NB\_BR)$}
  \label{algo:startnewbuffer}
  \begin{algorithmic}
    \IF{$length(curr\_buffer) == MAX\_BB$}
      \RETURN $True$
    \ENDIF
    \IF{$b != prev\_block+1$}
      \RETURN $True$
    \ENDIF
    \IF{$prev\_block != 0$ \textbf{and} $prev\_block \% NB\_BR $}
      \RETURN $True$
    \ENDIF
    \RETURN $False$
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}
  \caption{$concat\_rows()$}
  \label{algo:concatrows}
  \begin{algorithmic}
    \STATE $merged\_buffer \leftarrow list()$
    \FOR{$buffer in buffers$}
      \IF{$is\_complete\_row(buffer)$}
        \STATE $start\_new\_buffer \leftarrow False$
        \IF {$overlap\_slices(curr\_buffer, buffer)$}
          \STATE $start\_new\_buffer \leftarrow True$
        \ENDIF
        \IF {$length(curr\_buffer) + length(buffer) > buffer\_size$}
          \STATE $start\_new\_buffer \leftarrow True$
        \ENDIF
        \IF {$start\_new\_buffer$}
          \STATE $merged\_buffers.append(curr\_buffer.copy())$
          \STATE $curr\_buffer \leftarrow list()$
        \ENDIF
        \STATE $curr\_buffer.concat(buffer)$
      \ELSE
        \STATE $merged\_buffers.append(buffer)$ \COMMENT {Do nothing}
      \ENDIF
    \ENDFOR
  \end{algorithmic}
\end{algorithm}

\subsubsection{Scheduler constraint on memory}
\textbf{The idea} :
Now that we have bufferized the data loading according to the clustered strategy, there is still a problem remaining: the scheduler is a threaded one. It implies that there will be several buffers loaded in ``parallel" threads, although the RAM is shared by all the threads. In the clustered strategy paper, we choose the buffer size according to the amount of RAM available. If we do that while usign several threads to load the data, we end up loading several buffers at the same time with each buffer reaching the size of the maximum memory available. Therefore, our buffering will not work unless we force the scheduler to load the buffers sequentially. We need to constrain only the buffer loading tasks and not the other one in order not to loose the parallelism for computation. \\

% The HDD and SSD disks can only be sequentially accessed. It means that even if the threads are parallel, they will have access to the reading sequentially, one after the other. Which mean that it will do seeks between each switch of thread. Is that true?
% all the threads share the same memory space by definition of a thread
% keep in mind that threads are parallelism only whith the use of multicore computers.

\textbf{Dask's threaded Scheduler} :
Let us consider the so-called ``Asynchronous Shared-Memory Scheduler for Dask Graphs". From the docstrings of Dask we find that the state of the scheduler is divided in two collections of data structures regarding if they are ``Constant states" or ``Changing states". ``Changing states" are divided into two categories: ``data-related" states and ``job-related" states. \\

\noindent \textit{``Constant states"}
\begin{itemize}
  \item Dependencies: ${x: [a, b ,c]}$ a,b,c, must be run before x
  \item Dependents: ${a: [x, y]}$ a must run before x or y
\end{itemize}

\noindent \textit{Data-related states}
\begin{itemize}
  \item Cache: available, concrete data. (Dictionary)
  \item Released: Data that have been loaded, used and deleted and that we no longer need.
\end{itemize}

\noindent \textit{Job-related states}
\begin{itemize}
  \item Ready: FIFO stack of ready-to-run tasks.
  \item Running: Set of tasks that are being processed.
  \item Finished: Set of finished tasks.
  \item Waiting: Real time equivalent of dependencies.
  \item Waiting data: Data that is available for use. Real time equivalent of dependents.
\end{itemize}

 % has waiting data been taken into acount????

\textbf{Modification of the scheduler for safe buffering} :
Our goal is to load one buffer task at a time. To do this, we add two sets: $loading\_data$ and $delayed\_loading$ . In the first set we store the keys of the data loading tasks including one buffer task together with the memory size of the data being loaded. After having identified a task as being a buffer task, the pseudo-code to whether or not to launch this task is very simple as shown in Algorithm~\ref{algo:mainscheduling}: We predict if the amount of data stored in RAM will be too big after having loaded the buffer task in question. If so, we delay its processing by putting it into the $delayed\_loading$ set. Every time a buffer task has finished its processing, we look at the byte size of the first buffer task waiting in $delayed\_loading$ to see if it can be loaded.

% (currently it is allowed to load several buffers at the same time)

\begin{algorithm}
  \caption{$main\_scheduling\_function()$}
  \label{algo:mainscheduling}
  \begin{algorithmic}
    \WHILE{$size(ready) > 0$}
      \STATE $next\_task \leftarrow ready.pop(0)$
      \IF {$is\_buffer(next\_task)$}
        \IF {$launch\_buffer\_task(next\_task)$}
          \STATE $run(next\_task)$
        \ELSE
          \STATE $delayed\_loading.add(next\_task)$
        \ENDIF
      \ELSE
        \STATE $run(next\_task)$
      \ENDIF
    \ENDWHILE
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}
  \caption{$launch\_buffer\_task(next\_buffer\_task)$}
  \label{algo:launchbuffertask}
  \begin{algorithmic}
    \STATE $mem\_print \leftarrow size(cache) + size(waiting\_data) + size(loading\_data)$
    \IF {$already\_loading()$ \COMMENT{We are supposed to load only one buffer at a time}}
      \RETURN $False$
    \ENDIF
    \IF {$mem\_print + size(next\_buffer\_task) > memory\_size$}
      \RETURN $False$
    \ENDIF
    \RETURN $True$
  \end{algorithmic}
\end{algorithm}

In case the buffering task would not be desirable by any application, it is disactivated by default. To activate the scheduler optimization using clustered strategy, one can simply set the $io-optimizer.scheduler\_opti$ configuration setting to $True$.

\subsection{Experiment 2 - Assessing the splitting performance of our implementation}

\subsection{Experiment 3 - Assessing the reproducibility with other file formats}

%----------------------------------------
\section*{Results}
%----------------------------------------

%----------------------------------------
\section*{Discussion}
%----------------------------------------

%----------------------------------------
\section*{Conclusion}
%----------------------------------------

%----------------------------------------
\section*{Acknowledgment}
%----------------------------------------

Todo

%----------------------------------------
\section*{References}
%----------------------------------------

Todo

\end{document}
