\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{algorithmic, algorithm}
\usepackage{hyperref} % makes cross-refs (biblio, figures, algos, ...) clickable
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\newcommand{\logic}[1]{\color{red}\textbf{Logic/flow:}#1\color{black}}
\newcommand{\writing}[1]{\color{green}\textbf{Writing:}#1\color{black}}
\newcommand{\tristan}[1]{\color{orange}\textbf{From Tristan:}#1\color{black}}
\newcommand{\timothee}[1]{\color{blue}\textbf{From Timoth√©e:}#1\color{black}}

\begin{document}

\title{ Dask Rechunk for sequentially splitting, merging and rechunking multidimensional arrays }

\author{\IEEEauthorblockN{Timoth\'ee Gu\'edon, Val\'erie Hayot-Sasson, Tristan Glatard \\
  \IEEEauthorblockA{
    Department of Computer Science and Software Engineering, Concordia University, Montreal, Canada
  }}
}

\maketitle

\begin{abstract}
Todo.
\end{abstract}

\begin{IEEEkeywords}
multidimensional, array, split, merge, resplit, IO, processing, Dask, Python
\end{IEEEkeywords}

%----------------------------------------
\section{Introduction}
%----------------------------------------
% big data challenges
With the improvement of acquisition methods and the growth in the amount of data
available in several scientific domains such as health
sciences~\cite{bigdata_health}~\cite{Amunts1472}, geology~\cite{big_data_geology}
and astrophysics~\cite{biguniverse}, new big data challenges have emerged related
to the processing of large amounts of data, including ultra-high resolution
images. Big Brain, a human brain model providing microscopic data (20 micrometers) for
modeling and simulation~\cite{Amunts1472} is an example of ultra high resolution
images in the neuroscience field.

\subsection{Data storage on disk}
% explain storage order
Previous work focused on optimizing the data storage by looking for an optimal
chunk shape that would reduce the expected number of chunks to be retrieved by
any query~\cite{optimal_chuking} or by optimizing the ordering of the chunks
using space filling curves for example~\cite{optimal_chuking, openconnectomecluster}.
Instead, our approach is to leave the choice of the
data storage to the application as much as possible, as in~\cite{seqalgorithms}. We therefore assume that
the chunk shape and the data ordering in files are arbitrary but known.

For the sake of clarity and without loss of generality,
 we assume in this study that files are written in row-major order (a.k.a
``C" ordering), where the fastest moving dimension in the file is the last
dimension in the array, and the slowest moving dimension in the file is the first
dimension in the array. For example a 3D array with dimensions $i$, $j$ and $k$
would be written on disk by writing the complete columns in the k dimension first.
Our experiments use the HDF5~\cite{hdf5} file format as it is commonly used in the
scientific community and it is written in \texttt{C-order} by default.

\subsection{Multidimensional array chunking}
% use of chunking
Scientific data is often represented as multidimensional arrays stored in
chunks to facilitate processing and storage. Among other advantages, chunking
allows for efficient queries, flexibility in adding new
data~\cite{optimal_chuking}, parallel processing, and out-of-core
computations through block algorithms~\cite{matthew_rocklin-proc-scipy-2015}.
Moreover, as explained in~\cite{matthew_rocklin-proc-scipy-2015}, block
algorithms are ``necessary when data cannot be entirely loaded in memory".
\tristan{last sentence is redundant with last part of previous one.}
\timothee{to be discussed}

% need for tools to rechunk
Chunking multidimensional array requires tools to efficiently split,
merge, and ``resplit" or ``rechunk" data files. Previous work in~\cite{seqalgorithms}
showed that naive algorithms to split an array into several chunks or merge
array chunks into one output file perform very poorly due to millions of seeks
occurring on disk.

% why subarray extraction incurs seeks
Indeed, retrieving sub-arrays from an array stored on disk incurs seeks in two situations: (1) when an array block
is opened for reading or writing, and (2) when the reading or writing process
moves within the block to access a contiguous piece of data. For a 3D cuboid of shape $C = (C_i, C_j, C_k)$
 stored in row-major order,
each column of data in the k dimension is contiguously stored. There are therefore
$C_j \times C_i$ data columns that all require a seek. Although the seek
time depends on various parameters such as the distance in bytes between two
data columns, we assume that all seeks incur the same time overhead for the sake
of simplicity. Therefore our problem will be to minimize the number of seeks
required to access data.

\subsection{Problem definition}
We focus on 3D arrays for simplicity. Consider a 3D array of shape $R =
(R_i, R_j, R_k)$, stored as input blocks of uniform shape $I =
(I_i, I_j, I_k)$. Our goal is to rechunk input blocks into output blocks of
uniform but different shape $O = (O_i, O_j, O_k)$.

A rechunk algorithm (Algorithm~\ref{algo:generalrechunk}) takes as input a
list of input files \texttt{inFiles} of shape $I$, a list of output files
\texttt{outFiles} of shape $O$ and the amount of memory \texttt{m}
available for the rechunk. Based on a given strategy and taking $m$ into
account, the algorithm first defines an ordered list of buffers positions
\texttt{buffersList} (line 2) together with a \texttt{writing policy}. The
\texttt{buffersList} defines a partition of array $R$ and output files
may be covered by one or more buffers. The buffers are loaded sequentially
(line 4), and their data is stored in a cache (line 6). After each buffer load,
the \texttt{writing policy} is used by the algorithm to know when to write down
the data from the cache (lines 7 and 8). An example of a writing policy could be:
``write the data from the cache into the appropriate output file only when all
the data from that output file has been successfully loaded".

For simplicity, we require that all buffers in \texttt{buffersList} have
the same shape $B$. We define the ``rechunk problem" the problem of finding the
best writing policy, together with its associated buffer shape, to minimize the
number of seeks produced by rechunking the input array from a given chunk shape
$I$ to another chunk shape $O$, constrained by a fixed amount of memory $m$
available for the buffer. In this study we attempt to answer to this problem by
giving an implementation to the \texttt{getBufferPositions}-\texttt{getDataToWrite}
pair of functions. As you can see in Algorithm~\ref{algo:generalrechunk} there
are no safeguards preventing a bad writing policy to keep too much data in the
cache or a bad buffer shape to load too much data at a time; these issues have
to be addressed by \texttt{getBufferPositions}, too.

A lower bound on the number of seeks for the rechunk task is
$n_i + n_o$, with $n_i$ the number of input files and $n_o$ the number of output
files. Indeed, input and output files all have to be accessed at least once,
which requires a seek.

\begin{algorithm}
  \caption{General rechunk algorithm}
  \label{algo:generalrechunk}
  \begin{algorithmic}[1]
    \STATE \textbf{Inputs:} inFiles, outFiles, $m$
    \STATE buffersList, policy $\leftarrow$ getBufferPositions($I$,$O$,$m$)
    \STATE initialize(cache)
    \FOR{buffer in buffersList}
      \STATE bufferData $\leftarrow$ read(inFiles, buffer)
      \STATE cache.insert(bufferData)
      \FOR{(fileIndex, data) in getDataToWrite(cache, policy)}
        \STATE write(outFiles[fileIndex], data)
      \ENDFOR
    \ENDFOR

  \end{algorithmic}
\end{algorithm}

\subsection{The multiple and clustered strategies}
Special cases of the rechunk problem occur when $I=R$ (``split'' problem)
or $O=R$ (``merge'' problem). Two strategies have been introduced
in~\cite{seqalgorithms} to address these problems: the ``multiple" and the
``clustered" strategies. As explained in the problem definition, the rechunk
problem can be adressed in terms of Algorithm~\ref{algo:generalrechunk}
by finding the \texttt{getBufferPositions} function.
The strategies defined in ~\cite{seqalgorithms} for splitting and merging arrays
do not use any cache management as every buffer loaded is directly written down
in the destination output files. It is equivalent to defining the writing policy
as ``write all the cache into the appropriate output files". The only difference
between the strategies now lies in the buffer shape definition.

Focusing on the split problem $(I=R)$, a naive strategy defines the buffers as
having the same shape $O$ as the output files. The buffers are iteratively
loaded from $R$ and completely written into the appropriate output
file~\cite{seqalgorithms}. The clustered strategy however, reduces the number of
seeks done when reading the data by loading as much contiguous blocks of data
of shape $O$ from the input array as allowed by the available main memory (RAM).
This strategy loads data blocks one by one, block columns by block columns or
blocks slices by block slices, depending on the amount of main memory available
for the buffer. Using this strategy for rechunking would imply reading multiple
input files that are contiguous in the reconstructed image or reading the data
of contiguous output files by seeking into input files. In either case one can
find special cases in which the algorithm seeks in all dimensions.

The multiple strategy aims at not doing any seek while reading and writing.
Both the input file and the output files must be read/written contiguously. In
terms of Algorithm~\ref{algo:generalrechunk}, this means defining buffers as
contiguous parts of the input array. It is equivalent to extending the buffer
in the inverse of the storage order: $k \rightarrow j \rightarrow i$ in the case
of the row-major order. The tradeoff lies in switching between files
at each buffer loading. Using this strategy for the rechunk task would imply
reading contiguous columns or slices of data from the input files and writing it
contiguously in the output files. This would result in even more switches
between input and output files and one can find worst cases when using small
$I$ and $O$ shapes for example where a smarter strategy would be appreciated.

To the best of our knowedge however, no algorithm has been proposed for the
rechunk task. The algorithm presented in this study can be seen as an
adaptation of the multiple strategy to the rechunk task.

\subsection{Baseline solution}

A baseline/naive algorithm for the rechunk task would be to load one input file
at a time. It is equivalent to computing the buffers' positions in
Algorithm~\ref{algo:generalrechunk} using a buffer shape equal to $I$.
It is assumed that one input file can stand in memory ($m \geq I_iI_jI_k$). Each
buffer is loaded only once and the data loaded into the cache is directly
written down into the appropriate output files. The buffer order has no
implication on the number of seeks, so let us set the buffer order arbitrarily
to the storage order ($i \rightarrow j \rightarrow k$ in row-major for example).

One could compute the amount of seeks $s$ produced by such an algorithm as the
sum of the number of seeks done by processing each buffer (of shape $I$). The
number of output files to open and the number of seeks in each output file varies
according to the buffer's position however, we therefore analyze the number of
seeks globally. $s$ is the sum of:
\begin{itemize}
  \item the number of buffers that must be read: the number of input files
  \item the number of output files' opening
  \item the number of seeks done by writing into the output files
\end{itemize}

To compute the two last quantities, let us define $p_x$ the partition of $R_x$
by both the input and output files' borders. We then define $d_x$ the number of
distinct values in $p_x$:
$$d_x=length(p_x)$$
One can see $d_x$ as the number of times that the original image is being sliced
in dimension $x$ by either an output or an input file (see Figure x) or as the
number of shape mismatches between input and output files in dimension $x$.

Let us consider a given buffer (of shape $I$). In case of a mismatch in dimension
$k$ the buffer is divided in two parts in dimension $k$ which results in $2*I_i*I_j$
seeks: two by input data column or one by output data column, with two output
data column per input data column. Any mismatch in dimension $i$ or $j$ would
cut the buffer at the end of an output data column, and is therefore included in
the number of seeks due to the mismatch in $k$. The same observation can be made
between dimension $j$ and $i$: the seeks occuring from a mismatch in $i$ are
included in the seeks occuring by a mismatch in $j$. Therefore, the number of
seeks at write time is computed in one of three distinct cases:
(1) $I_k \neq O_k$, (2) $I_k = O_k$ and $I_j \neq O_j$ and (3) $I_k = O_k$,
$I_j = O_j$ but $I_i \neq O_i$. Equation~\ref{eq:1} gives the amount of seeks
done by writing data in output files for the whole baseline algorithm.
The case is indicated using $\alpha$, defined as: \\
$$\alpha_x = \begin{cases}
   1 & \mathrm{if} I_x \neq O_x \leftrightarrow d_x > 0 \\
   0 & \mathrm{otherwise}
\end{cases}$$

\begin{multline} \label{eq:1}
s_{write} = [(d_k+1)R_iR_j]\alpha_k \\ + [(d_j+1)R_i\frac{R_k}{I_k}](1-\alpha_k)\alpha_j \\ + [(d_i+1)\frac{R_j}{I_j}\frac{R_k}{I_k}](1-\alpha_k)(1-\alpha_j)\alpha_i
\end{multline}

The seeks for opening output files are included in Equation~\ref{eq:1}.
We say that there is a \texttt{shape mismatch} in a given dimension $x$ if
$I_x \neq O_x$.
In case of no shape mismatch, no seek occur when writing the data into the output
files apart from opening the output files. The number times that an output file
has to be opened would be computed as $(d_i-1)*(d_j-1)*(d_k-1)$. However, not
shape mismatch imply no rechunk problem so we do not include this value in $s$.

Finally, an equation for $s$ is: $s = s_{write} + s_{read}$,
with $s_{read} = \frac{R_i}{I_i} \frac{R_j}{I_j} \frac{R_k}{I_k}$, the number of
input files a.k.a. buffers to read.


 \begin{table}[ht]
  \centering
  \caption{Shapes used for the experiment on the baseline seek model}

   \begin{tabular}[t]{c c c c}
   \hline
   Mismatch & R & B=I & O \\
     \hline\hline
     k,j,i & (240,240,240) & (30,30,30) & (20,20,20) \\
     \hline
     j,i & (240,240,240) & (30,30,\textbf{20}) & (20,20,20) \\
     \hline
     i & (240,240,240) & (30,\textbf{20},\textbf{20}) & (20,20,20) \\
     \hline
   \end{tabular}

   \label{tab:expseekmodel}

\end{table}

\begin{figure}[h]
\centering
\includegraphics[scale=0.55]{./figures/baseline_math_model.png}
\caption{Illustration of seek gains when removing one shape mismatch at a time.
}
\label{fig:baseline_math_model}
\end{figure}

It seems from Equation~\ref{eq:1} that unless the dimensions of the input and
output files match, a considerable amount of seeks will occur, the number of
seeks being factors of $R_k$, $R_j$ and/or $R_i$. Also, a shape mismatch in the
$k$ dimension seems to be more costly than a shape mismatch in the $j$ dimension,
which is itself more costly than a mismatch in dimension $i$ (assuming that the
files are stored in C-order). The seek model has been implemented to confirm
these theories by an experiment on cubic shapes
(Figure~\ref{fig:baseline_math_model}). The shapes used for the experiment are
described in Table~\ref{tab:expseekmodel}.

\subsection{Dask}

Dask is a popular Python package enabling parallel and out-of-core
computation in the SciPy ecosystem. It represents computations as task
graphs that are dynamically executed by one of several schedulers offered
by Dask including the single-threaded, the multi-threaded, the
multi-process, and the distributed schedulers. Custom schedulers can also
be implemented. Dask graphs can be used out-of-the-box or through built-in
APIs. For example, \texttt{dask.array} is a parallel and out-of-core Numpy
clone, and
\texttt{dask.dataframe} is a Pandas clone. A Dask graph is implemented in
plain Python as a dictionary with any hashable as keys and any object as
values. More precisely, a "Value" is any object different than a task and a
"Task" is a tuple with a callable as first element.

We focus on the \texttt{dask.array} collection, a data structure designed for
multi-dimensional array processing using blocked algorithms.

\subsection{Contributions}
This paper makes the following contributions:
\begin{itemize}
  \item Definition of the rechunk problem for multidimensional arrays
  \item A sequential algorithm to efficiently rechunk multidimensional arrays
  \item An open implementation of this algorithm in Dask, in a library called Dask Rechunk.
  \item An open implementation in Dask of the ``clustered" split and merge strategy described in~\cite{seqalgorithms}, in Dask Rechunk too.
\end{itemize}

%----------------------------------------
\section{The ``keep" algorithm}
%----------------------------------------

As mentioned previously, like the split and merge strategies the baseline
algorithm for the rechunk problem empties the cache at each iteration. In a
split/merge/rechunk problem a lot of seeks occur in case of a shape mismatch,
that is, when a data column loaded in memory is split between two output files.
Therefore, a solution to reduce the number of seeks seems to use a ``keep''
strategy, keeping some data in the cache while it cannot be written contiguously
in output files. Such a strategy is presented in this section.

\subsection{The keep strategy}
In the cache (Algorithm~\ref{algo:generalrechunk}), the data that is not
contiguous in its output file of destination is called \texttt{extra data}.
The keep strategy first consists in finding a buffer shape covering at least
one output file completely, i.e. $B_x>O_x$ for all dimensions $x$. If $m$ is too
small for such a buffer shape, then the keep strategy tries to find a buffer
shape as closed as possible from the optimal buffer shape. Using such an optimal
buffer shape and being able to keep all the extra data into memory during the
whole rechunk process would incur the minimum number of seeks possible: $n_i + n_o$.
Indeed, it is equivalent to writing an output file only when all its data is in
cache.
The implementation of the keep strategy is equivalent to implementing
\texttt{getBufferPositions} in Algorithm~\ref{algo:generalrechunk} to find a
buffer shape closed to the optimal buffer shape, and defining the write policy
as ``write all the data that is not extra data".

\subsection{Input aggregates}
Our goal is to find the optimal buffer shape such that $B_x>O_x$ in any dimension $x$.
If $I_x > O_x$, then $B_x$ can be set to $I_x$. If $I_x < O_x$ however, $B_x$
must be a multiple of $I_x$ in order to keep reading each input file in one seek.
We define an input aggregate as being the minimum aggregate of input files that
covers one output file completely. In particular, it is the input aggregate that
covers the first output file (indexed $(0,0,0)$) in the original image being
rechunked. The best buffer shape for the keep strategy is therefore the shape of
an input aggregate. We call this shape $\Lambda$.

\subsection{Stretching the buffer in the inverse storage order}
To get a buffer shape close to $\Lambda$ we define an algorithm
\texttt{getBufferShape} in \texttt{getBufferPositions} that stretches the
buffer shape step by step. At each step, the algorithm estimates how much the
buffer can be stretched in one direction while keeping the remainders into
memory. The problem of what dimension to increase first still stands. A
strategic order seems to be to stretch the buffer in the direction which saves
the maximum number of seeks first. Given the analysis of the baseline algorithm,
such an order is the inverse of the storage order i.e.
$k \rightarrow j \rightarrow i$ in the row-major order
$i \rightarrow j \rightarrow k$.

\subsection{Impact of the buffer order on performance}
Using the keep strategy, one may order the buffer loadings to reduce the maximum
quantity of extra data stored in memory, hence, reducing the amount of seeks.
For example, if an overlap occurs only in the $k$ axis, loading the next buffers
in this direction will enable recycling the extra data kept in memory, resulting
in a smallest memory consumption over time. The memory saved thanks to a smart
ordering could enable the storage of more overlaps in memory using the
``keep strategy", further reducing the overall number of seeks.

As explained in the discussion, the buffer ordering problem is complex and does
not seem easily solvable.
This study uses a naive order which is again the inverse of the storage order.
Thanksfully, the impact of the buffer ordering on performance can be
mitigated. Indeed, the impact of the buffer ordering depends on the size of the
mismatches. One can reduce the amount of extra data by using smallest chunks: Even
if the overlap between the input and output files is big with respect to their
size, the area/volume of the overlap will be kept small.

%----------------------------------------
\section{The buffer extension algorithm}
%----------------------------------------

The buffer extension algorithm aims at extending the buffer shape from
(1,1,$\Lambda_k$) to the input aggregate shape $\Lambda$. Note that we assume
that $m$ is large enough to store a buffer of shape (1,1,$\Lambda_k$). It means
that we can read one complete data column from an input file and keep the
remainder in memory for the next buffer. If it was not the case the keep
algorithm would not give a significant improvement in the number of seeks
produced by the rechunk task, compared to the baseline algorithm.

In this analysis, we express the quantity of memory used by an array as the
number of voxels it contains. It is equivalent to saying that the number of
bytes per voxel is 1. With $\alpha$ the number of bytes per voxel in the storage
device, $m$ is defined as $m/\alpha$ in the following computations.

The following subsections covers how we estimate the amount of memory required
by the keep strategy to know how much the buffer can be stretched in a given
direction while keeping the extra data in memory. The amount of memory required
is the maximum memory consumption reached during the execution of the keep algorithm.
To estimate this amount, we first need to define what a remainder volume is.

\subsection{Remainder volumes}

A buffer of shape $\Lambda$ can be divided in
8 parts or ``volumes" (Figure~\ref{fig:nomenclature_overlaps}).
7 out of these 8 volumes are called \texttt{remainder volumes} because
they represent the overlap between the input aggregate and the output files on
its border. These 7 remainder volumes enclose an 8th part that is composed of
input files that are either complete or which complementary part have already
been loaded by a previous buffer. This means that any complementary part is either
in memory (it has been kept in cache according to the keep strategy) or it has
been written down previously. Therefore, this 8th volume cannot be kept by the
keep strategy and is not considered a remainder. For each buffer, each of volume
is indexed following the buffer order $F_0$ to $F_7$, with $F_0$ being the
non-remainder volume. If the buffer is smallest than the input aggregate or if
there is no shape mismatch in a given dimension, it may be that a volume size
is set to 0.

\begin{figure*}[h]
\centering
\includegraphics[scale=0.4]{./figures/new/nomenclature_overlaps.png}
\caption{Division of a buffer into 8 parts indexed according to the storage
order, 7 of which are remainder volumes.}
\label{fig:nomenclature_overlaps}
\end{figure*}

\subsection{Maximum memory consumption}

Having partitioned the buffers into volumes, the maximum memory consumption is
computed from two pieces of information: The maximum number of each volume we
must keep during the process and the maximum size of each volume.

In the buffer extension algorithm, the buffer is stretched in one dimension at a time.
When stretching the buffer, we compute the maximum length of the buffer possible
in the dimension considered, while ensuring that the remainder volumes can be
kept into memory according to the \texttt{keep} algorithm. To that aim, we need
a formula that computes the maximum amount of times that we have to keep each
remainder volume, together with the maximum size of those volumes. For example, if
we consider stretching the buffer in the $j$ dimension, we want to know how big
$B_j$ can be such that the remainders are kept in memory by the \texttt{keep}
algorithm for later use, given the maximum amount of memory available, $m$.

We define $\Sigma$, the maximum amount of data reached during the execution
of the keep algorithm in terms of the number of volumes to be kept. From the
previous sections we assume that the buffer order is the inverse of the storage order.
In this order, the $F_1$ volume stored from a given buffer loading is recycled
in the next one. Therefore there can be only one $F_1$ volume in cache at a
given time. For any buffer, $F_2$ and $F_3$ are kept in memory until the next
buffer in the $j$ dimension recyles them. Therefore they can be present in cache
$n$ times at a maximum, with $n$ the number of buffers in a buffer column (the
number of buffers in dimension $k$). Volumes 4 to 7 can only be recycled by the
next buffer in the $i$ dimension. Therefore, the algorithm must read an entire
buffer slice before being able to remove them from the cache. They are kept a
maximum of $N$ times, with $N$ the number of buffers in a slice of the
reconstructed image. Last but not least, a buffer must be loaded at each step of
the keep algorithm. This gives us the following formula for $\Sigma$:

\begin{equation} \label{eq:2}
\Sigma = F_1 + n(F_2 + F_3) + N(F_4 + F_5 + F_6 + F_7) + B_iB_jB_k
\end{equation}

Finally, to find the maximum size of each volume one must know the maximum
overlap length between the buffer and the output files on its border. One can
either compute all possibilities and take the maximum in each dimension if it is
not too costly or use the following upper bound: By definition of an input
aggregate, the overlap between any buffer and its bordering output files it at
maximum $O_x$ in dimension $x$.

\subsection{The getBufferPositions function}

In order to compute $\Sigma$, the volumes' sizes need to be computed using the
following nomenclature (Figure~\ref{fig:nomenclature_overlaps}):
Given a buffer shape $B$ and the output file shape $O$, we define $C_d(x)$ as
the overlap length between the buffer and an overlaping output file in direction
$d$ for the $x{th}$ buffer. Let us define $\Omega$ and $\Theta$, that are used
to define upper bounds in the volumes sizes formulas. $\Omega_d(x)$ is the
equivalent of $C_d(x)$ if the buffer was of shape $\Lambda$, and $\Theta_k(x)$
is the difference between $B_d$ and $\Omega_b$, with $B=\Lambda$.
These metrics are computed as follows:
$$C_d(x) = (x+1)B_d mod(O_d)$$
$$\Omega_d(x) = (x+1)\Lambda_d mod(O_d)$$
$$\Theta_d(x) = \Lambda_d - \Omega_d(x)$$

Given equation~\ref{eq:2} and the maximum size of the volumes, we can now
stretch the buffer shape one dimension at a time using simple equations to ensure
that the maximum amount of memory consumed during the process will stay below the
amount of memory available. Such computations are given in
Appendix~\ref{bufferExtensionAlgorithm}.
Algorithm~\ref{algo:bufferextensionalgorihm} summarizes the computations into a
pseudocode for the buffer extension algorithm.

\begin{algorithm}
  \caption{Pseudocode of the buffer extension algorithm}
  \label{algo:bufferextensionalgorihm}
  \begin{algorithmic}[1]
    \STATE \textbf{Inputs:} $\Omega_{max}$, $\Lambda$, $m$
    \STATE $\Omega \leftarrow \Omega_{max}$
    \STATE $\Theta = (\Lambda_i - \Omega_i, \Lambda_j - \Omega_j, \Lambda_k - \Omega_k)$
    \STATE $B \leftarrow (1,1,\Lambda_k)$

    \STATE $\phi = \lfloor \frac{m}{\Omega_k + \Lambda_k} \rfloor$
    \STATE $B_j = \begin{cases}
      \Theta_j & \textrm{if }\phi \geq \Theta_j \\
      1 & \textrm{if }\phi = 0 \\
      \phi & \textrm{else}
    \end{cases}$

    \IF{$B_j \neq \Theta_j$}
      \RETURN $B$
    \ENDIF

    \STATE $\phi = \lfloor \frac{m-\Theta_j(\Omega_k\Lambda_k)}{\Lambda_k(n+1)} \rfloor$
    \STATE $B_j = \begin{cases}
      \Lambda_j & \textrm{if }\phi \geq \Lambda_j \\
      B_j & \textrm{if }(B_j+\phi) = 0 \\
      B_j + \phi & \textrm{else}
    \end{cases}$

    \IF{$B_j \neq \Lambda_j$}
      \RETURN $B$
    \ENDIF

    \STATE $\phi = \lfloor \frac{m}{\Omega_k\Theta_j + n\Omega_j\Lambda_k + \Lambda_j\Lambda_k} \rfloor$
    \STATE $B_i = \begin{cases}
      \Theta_i & \textrm{if }\phi \geq \Theta_i \\
      1 & \textrm{if }\phi = 0 \\
      \phi & \textrm{else}
    \end{cases}$

    \IF{$B_i \neq \Theta_i$}
      \RETURN $B$
    \ENDIF

    \STATE $\phi = \lfloor \frac{m-\Theta_i(\Omega_k\Theta_j + n\Omega_j\Lambda_k + \Lambda_j\Lambda_k)}{(N+1)\Lambda_j\Lambda_k} \rfloor$
    \STATE $B_i = \begin{cases}
      \Lambda_i & \textrm{if }(B_i+\phi) \geq \Lambda_i \\
      B_i & \textrm{if }\phi = 0 \\
      B_i+\phi & \textrm{else}
    \end{cases}$

    \RETURN $B$

  \end{algorithmic}
\end{algorithm}

%----------------------------------------
\section{Methods}
%----------------------------------------
\tristan{This can't be called methods, the algo definition is already methods.}
Before diving into the implementation of the keep algorithm we first designed
an experiment to prove that dask.array was subject to the seek problem. To that
aim we created a random array from a uniform distribution and stored it as a
HDF5 file for later processing. The array had a shape of x which represents 1/8
of the Big Brain size. The experiment then consisted in splitting and merging
the array with dask using two different chunk shapes: one of them doing more
seeks than the other. We did this experiment on both HDD and SSD to see if the
results were also visible when using an SSD which is suposedly less affected by
seeks. The results of this experiment showed that dask was indeed subject to the
seek problem. See the "Results" section for more details.

In order to see if a strategy to reduce the number of seeks was effective, we
implemented and tested the "clustered" strategy for splitting and merging
multidimensional arrays. We chose this strategy first because it seemed simpler
to implement and study~\cite{seqalgorithms} showed that such a strategy was
working. It means that if it failed the problem would be more likely to come
from the implementation or dask than from the algorithm itself. We also know
from~\cite{seqalgorithms} that the difference between the naive and clustered
strategies should be large enough to be visible in the processing time. The
shapes used for the experiment are shown on the table x. The implementation
details of the clustered strategy are discussed in the appropriate section and
again, the results are presented in the "Results" section. The code of the
experiment is available in a dedicated repository on Github.

After these two preliminary experiment, we implemented a simplified version of
the keep algorithm due to the difficulty to implemlent such an algorithm in a
task graph (see section "Implementation details"). In order to evaluate the
efficiency of the keep algorithm we compare it against vanilla dask on local
computer. To be fair we used dask with one thread as required for our
implementation but also with the classic multi-threaded  scheduler as it is the
default when using dask.array. In order to compare both implementations to a
naive rechunk, we also added a plain Python implementation to the benchmark. For
the experiments presented below we built a random 3D array of the size of Big
Brain, drawn from a uniform distribution. Once again, the array is initially
stored into an HDF5 file.

We did three experiments on the keep algorithm. The first one consisted in
comparing the different implementations in the case where the keep algorithm is
supposed to be the most effective i.e. when the buffer is equal to the input
aggregate $B_x=\Lambda_x$. In particular, three interesting cases are when
$B=(1,1,\Lambda_k)$, $B=(1,\Lambda_j, \Lambda_k)$ and $B=\Lambda$. Those three
cases represent ideal cases with different amount of data available. This
experiment aimed at (1) showing if the keep algorithm worked, (2) seeing how much it
can improve the processing speed and (3) how much gain it represents to be able to
stretch the buffer in each dimension.

In the second experiment, a more realistic case has been tested. In this case,
$O~=I$ which is more likely to happen in real life. Although in a realistic
scenario $O$ and $I$ would be relatively small, we also tested bigger shapes to
see the impact on performance and if one implementation was more resilient than
another.

Finally, the particular case of an important shape mismatch was tested. The cases
where $O>>I$ and $O<<I$ are equivalent, as in both cases the input aggegate
will be quite big. This is supposed to be a bad case for the keep algorithm
as extending the buffer to $\Lambda$ will be more complicated. For this
experiment, we fixed $m$ and $I$ and then ran multiple times the algorithms
while increasing $O$.

%----------------------------------------
\section{Implementation details}
%----------------------------------------

\subsection{Clustered strategy}

As explained in the introduction, daks represents computations by a task graph.
Implementing the clustered strategy consisted in modifying that graph. To that
aim, we implemented an optimization function to create "buffer" tasks in the
graph.

The optimization starts by converting the task graph into a mathematical
directed graph for use by a BFS (Breadth First Search) algorithm. More
precisely, we implement it as adjacency lists. The BFS algorithm allows us to
find and store tasks by type for later processing. Assuming that the whole array
is being processed, we find the appropriate buffering scheme from $I$, $O$ and
$m$, according to the algorithm in~\cite{seqalgorithms}. The buffering scheme
specifies if the algorithm loads buffers block by block, block columns by
block columns or block slices by block slices.

We then update the data loading tasks to force dask to load a whole buffer at
a time instead of small chunks. Finally, we modify the dependent tasks to make
them use our new buffer tasks. According to the clustered algorithm, all buffers
do not necessarily have the same shape, that is why we could not use the
\texttt{dask.array.rechunk} method.

The default scheduler for dask.array is the multi-threaded scheduler. It means
that at the beginning of the execution dask dispatches some tasks that have
no dependencies into different threads. The problem is that the clustered
strategy tries to use all the memory available for each buffer, and such buffer
tasks are the one with no initial dependencies. Therefore, we needed to
modify dask's scheduler to make it load one buffer only after the previous one
and its dependent tasks have ended. This avoid running out of memory during the
processing.

\subsection{The keep algorithm}

The buffer extension algorithm described in Appendix A has been direclty
implemented in plain Python \tristan{You cannot rely on an Appendix to present the algorithm. The bulk of it must be presented here, in a
concise way}. Implementing the last part of the algorithm
consisted in: (1) creating the buffer tasks, (2) dispatching the different data
parts loaded by each buffer into the appropriate output files, (3) simulating
the cache to keep remainders in memory between buffer loadings.

This time, the buffer task creation was straightforward as it is assumed by the
algorithm that the buffers constitute a partition of the whole array. For the
second and third part, we used the \texttt{dask.array.store} method that
requires input arrays as argument, together with the output files in which to
store the data and the indices of each data part in the output files. To
automatically compute such information, we proceeded as follows. We first
compute, for each output file, the list of each constitutive subarrays, with
subarrays defined by the intersection of input and output files and buffers.
When each output file ``knows" which part from which buffer are required, we
merge some of them according to the keep strategy to enforce the fact that
a given data part of a given output file has to be stored at once. By doing this
we create dependencies in the task graph. Such dependency tells dask that it
needs to load two buffers before writing a given subarray for example.

\subsection{Dask Rechunk}

Both implementations are available in a same Python package called \texttt{Dask Rechunk}. It
contains tests with 99\% coverage and is available on PyPI (The Python Package
Index). Dask Rechunk provides a simple API to use the split, merge and rechunk
algorithms described in this study (figure x).

%----------------------------------------
\section{Results}
%----------------------------------------

%----------------------------------------
\section{Discussion}
%----------------------------------------

\subsection{The buffer ordering problem}
The buffer ordering problem can be modeled as follows: We can reprensent the
problem as a complete bidirectional graph in which each vertex is a buffer. At
initialization, we must choose a first buffer as an entry point. Let us define
a path in the graph as visitation order of all buffers in the graph. One buffer
cannot appear twice in the list. Finally, let us define a cache that contains
the data currently in main memory. We define the buffer ordering problem as the
problem of finding the optimal path such that the amount of memory used by the
cache is kept minimal during the process. For each buffer, we load some data
into the cache and free some of it (writing into output files). The amount of
data released is different depending of the buffers previously visited and each
buffer can only be visited once which can be reprensented by removing all edges
pointing to a visited vertex except the one coming from the previously visited
vertex. One may solve this problem by using a greedy algorithm but it would
incur more infering at runtime and a potentially complex algorithm to run.
We decided to keep things simple using a naive buffer order, the storage order,
as the goal of this study is primarily to assess if the keep algorithm works.

\subsection{Breaking the buffers}
To even reduce the maximum amount of memory used during the rechunk process, we
could read the input files one by one instead of enforcing dask to read a whole
buffer at a time, provided that the input files' parts are read in the right
order (following the buffer order). The idea of reading an entire buffer at a
time came from the clustered and multiple strategies but we realized afterwards
that this could be beneficial to break the buffers into input files' parts. We
can see in Equation (2) that it would result in replacing $B_iB_jB_k$ by
$I_iI_jI_k$ or less if part of a file is loaded. This idea would only be
beneficial in the case where $B_x>I_x$. Indeed, in the other case, the buffer is
loaded anyways.

\subsection{ROI extraction problem}
The Region Of Interest (ROI) extraction problem is a related problem that still needs
to be adressed. A solution using chunking as been introduced in []. The authors
define an array partitioned into chunks of equal shapes and then define a
query as an arbitrary subarray of the input, chunked, array. They define the
optimal chunking problem as finding the optimal chunk such that the expected
number of chunks retrieved to answer the query is minimal. In our opinion, the
solution in [] is limited due to the need of historical or theoretical workload
and the necessity to rechunk the input array into an ``optimal" chunk shape. We
would prefer letting the application choose the appropriate chunk shape
regarding its needs and not needing to estimate the processing workload. We
define the ROI extraction problem as follows: Finding an algorithm that takes
as input an arbitrary chunk shape and extract the ROI data from the chunks with
the less number of seeks as possible.

\subsection{Solving three problems at once}
As stated in the introduction, the split and merge tasks are special cases of
the rechunk task. This observation leads us to think that maybe one could find
one optimal algorithm for the split, merge and rechunk tasks.

If we were to use the keep algorithm with $I=R$, we would read the input data
in slices, exactly like the multiple strategy. The only difference between the
two strategies, however, is that if some remainders appear at the bottom of the
buffer, the keep algorithm would keep it to try to read and write files in one
seek. This is what we meant by "a smarter adaptation of the multiple strategy
to the rechunk task": We not only try to limit seeking into the files but we
also try to limit switching between the files. It would be interesting to
compare the two algorithms for the split/merge tasks to see if the keep
implementation brings any kind of improvement.

\subsection{Towards distributed systems}
A future work would be to find distributed versions of the split/merge/rechunk
algorithms. Lots of scientists use HPC (High Performance Computing) clusters
regularly which brings considerations about how to use such distributed
algorithms with Lustre for example, a commonly used filesystem for HPC. Dask
also provides a distributed scheduler that seems to be quite efficient. It is
now recommended for use, even on local computers (using one node).

%----------------------------------------
\section{Conclusion}
%----------------------------------------

%----------------------------------------
\section{Acknowledgments}
%----------------------------------------

\bibliography{Bibliography}
\bibliographystyle{ieeetr}

\appendices

\section{Buffer extension algorithm}
\label{bufferExtensionAlgorithm}

For the $x^{th}$ buffer, the volumes' sizes are:

$\begin{cases}
F_1 = \Omega_k min(B_j, \Theta_j) min(B_i, \Theta_i) \\
F_2 = \Theta_k max(0, min(B_j - \Theta_j, \Omega_j)) min(B_i, \Theta_i) \\
F_3 = \Omega_k max(0, min(B_j - \Theta_j, \Omega_j)) min(B_i, \Theta_i) \\
F_4 = \Theta_k \Theta_j max(0, min(B_i-\Theta_i, \Omega_i)) \\
F_5 = \Omega_k \Theta_j max(0, min(B_i-\Theta_i, \Omega_i)) \\
F_6 = \Theta_k \Omega_j max(0, min(B_i-\Theta_i, \Omega_i)) \\
F_7 = \Omega_k \Omega_j max(0, min(B_i-\Theta_i, \Omega_i))
\end{cases}$

We are only interested in the maximum amount of memory that will be reached by
the algorithm. To that aim, we will not evaluate the above formula for each $x$
but we will replace each $\Omega_d(x)$ by its maximum in $\Sigma$. By definition
of $\Omega_d(x)$, an upper bound is $O_d$ but one can find the exact maximum
value by computing $\Omega_d(x)$ for all $x$, for each dimension $d$.

In the following paragraphs, we are finding formulas to extend the buffer one
dimension at a time, for use in the buffer stretching algorithm.

\subsection{Formulas of the buffer extension}
\subsubsection{Keeping F1}

We first extend the buffer in the $j$ dimension to keep $F_1$.

\noindent $$F_1 = \Omega_k B_j B_i = \Omega_k B_j$$
$$\Sigma = F_1 + B_iB_jB_k$$
$$\Sigma = B_j (\Omega_k + \Lambda_k)$$
$$\Sigma \leq m \Leftrightarrow B_j (\Omega_k + \Lambda_k) \leq m$$
$$\Sigma \leq m \Leftrightarrow B_j \leq \frac{m}{\Omega_k + \Lambda_k}$$

We define $\phi$, the maximum value for $B_j$:
$$\phi = \lfloor \frac{m}{\Omega_k + \Lambda_k} \rfloor$$

When extending the buffer in the $j$ dimension, $B_i$ stays at 1, so by
definition of $F_1$ the maximum value that $F_1$ can take is $\Omega_k\Theta_j$.
$$B_j = \begin{cases}
  \Theta_j & \textrm{if }\phi \geq \Theta_j \\
  1 & \textrm{if }\phi = 0 \\
  \phi & \textrm{else}
\end{cases}$$

If $B_j=\Theta_j$, then we can continue stretching $B$ in the $j$ direction to
try to keep $F_2$ and $F_3$ areas.

\subsubsection{Keeping F2 and F3}

Let us define $\delta_j$, the amount we will try to add to $B_j$, such that:
$$B_j - \Theta_j = \delta_j$$
$$B_j = \delta_j + \Theta_j$$

From the previous subsection, $F_1$ is of size:
$$F_1 = \Omega_k \Theta_j B_i = \Omega_k \Theta_j$$
$F_2$ and $F_3$ are defined in terms of $\delta_i$:
$$F_2 = \Theta_k \delta_j B_i = \Theta_k \delta_j$$
$$F_3 = \Omega_k \delta_j B_i = \Omega_k \delta_j$$

We get:
$$\Sigma = F_1 + n(F_2+F_3)$$
$$\Sigma = \delta_j\Lambda_k(n+1) + \Theta_j(\Omega_k\Lambda_k)$$
$$\Sigma \leq m \leftrightarrow \frac{m-\Theta_j(\Omega_k\Lambda_k)}{\Lambda_k(n+1)}$$
$$\phi = \lfloor \frac{m-\Theta_j(\Omega_k\Lambda_k)}{\Lambda_k(n+1)} \rfloor$$
$$B_j = \begin{cases}
  \Lambda_j & \textrm{if }\phi \geq \Lambda_j \\
  B_j = \Theta_j & \textrm{if }(B_j+\phi) = 0 \\
  B_j + \phi & \textrm{else}
\end{cases}$$

Again, if $B_j=\Lambda_j$, we continue to stretch the buffer, this time in the
$i$ dimension as $B$ equals $\Lambda$ in the $k$ and $j$ direction.

\subsubsection{Increasing F1, F2 and F3 in the ith dimension}
$$F_1 = \Omega_k\Theta_jB_i$$
$$F_2 = \Theta_k\Omega_jB_i$$
$$F_3 = \Omega_k\Omega_jB_i$$
$$\Sigma = B_i(\Omega_k\Theta_j + n\Omega_j\Lambda_k + \Lambda_j\Lambda_k)$$
$$\Sigma \leq m \leftrightarrow B_i \leq \frac{m}{\Omega_k\Theta_j + n\Omega_j\Lambda_k + \Lambda_j\Lambda_k}$$
$$\phi = \lfloor \frac{m}{\Omega_k\Theta_j + n\Omega_j\Lambda_k + \Lambda_j\Lambda_k} \rfloor$$

$$B_i = \begin{cases}
  \Theta_i & \textrm{if }\phi \geq \Theta_i \\
  1 & \textrm{if }\phi = 0 \\
  \phi & \textrm{else}
\end{cases}$$

If $B_i=\Theta_i$, we continue to stretch the buffer.

\subsubsection{Keeping F4, F5, F6, F7}

$$\begin{cases}
  F_1 = \Omega_k\Theta_j\Theta_i \\
  F_2 = \Theta_k\Omega_j\Theta_i \\
  F_3 = \Omega_k\Omega_j\Theta_i \\
  F_4 = \Theta_k\Theta_j\delta_i \\
  F_5 = \Omega_k\Theta_j\delta_i \\
  F_6 = \Theta_k\Omega_j\delta_i \\
  F_7 = \Omega_k\Omega_j\delta_i \\
  B_i = \Theta_i + \delta_i \\
  B_j = \Lambda_j\\
  B_k = \Lambda_k\\
\end{cases}$$

$$\Sigma = F_1 + n(F_2 + F_3) + N(F_4 + F_5 + F_6 + F_7) + B_iB_jB_k$$
$$\Sigma = F_1 + n(F_2 + F_3) + N(F_4 + F_5 + F_6 + F_7) + (\Theta_i + \delta_i)\Lambda_j\Lambda_k$$
$$\Sigma = \Theta_i(\Omega_k\Theta_j + n\Omega_j\Lambda_k + \Lambda_j\Lambda_k) + (N+1)\delta_i\Lambda_j\Lambda_k$$

$$\Sigma \leq m \leftrightarrow \delta_i \leq \frac{m-\Theta_i(\Omega_k\Theta_j + n\Omega_j\Lambda_k + \Lambda_j\Lambda_k)}{(N+1)\Lambda_j\Lambda_k}$$
$$\phi = \lfloor \frac{m-\Theta_i(\Omega_k\Theta_j + n\Omega_j\Lambda_k + \Lambda_j\Lambda_k)}{(N+1)\Lambda_j\Lambda_k} \rfloor$$

$$B_i = \begin{cases}
  \Lambda_i & \textrm{if }(B_i+\phi) \geq \Lambda_i \\
  B_i = \Theta_i & \textrm{if }\phi = 0 \\
  B_i+\phi & \textrm{else}
\end{cases}$$

The algorithm stops here, as if $B_i=\Lambda_i$, then the buffer has been
successfully stretched to the input aggregate shape, $\Lambda$.

\end{document}
